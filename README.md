# ğŸ“‰ Customer Churn Prediction Model

This project focuses on predicting customer churn using machine learning techniques. It leverages a real-world dataset from a telecom company to analyze customer behavior and determine which customers are at risk of leaving. The solution includes full data preprocessing, model training, evaluation, and result interpretation using Python and scikit-learn.

---

## ğŸ§  Problem Statement

Customer churn has a direct impact on a businessâ€™s profitability. It is more cost-effective to retain existing customers than to acquire new ones. The goal of this project is to build a predictive model that identifies customers likely to churn, enabling businesses to take proactive retention measures.

---

## ğŸ“Š Dataset Overview

**Source:** [Telco Customer Churn Dataset - Kaggle](https://www.kaggle.com/blastchar/telco-customer-churn)

**Columns:**  
The dataset includes 21 features such as:

- Customer demographics (gender, senior citizen, partner, dependents)
- Account information (tenure, contract type, paperless billing)
- Services used (InternetService, StreamingTV, OnlineBackup)
- Financial attributes (MonthlyCharges, TotalCharges)
- Target variable: `Churn` (Yes/No)

---

## ğŸ“ Project Structure

Customer-Churn-Prediction-Model/
â”œâ”€â”€ Telco-Customer-Churn.csv # Original dataset
â”œâ”€â”€ Untitled.ipynb # Data exploration & preprocessing
â”œâ”€â”€ Untitled2.ipynb # Model training & evaluation
â”œâ”€â”€ churn_model.joblib # Serialized trained model
â””â”€â”€ README.md # Project documentation


---

## ğŸ” Project Workflow

### 1. Exploratory Data Analysis (EDA)
- Identified distribution of churned vs retained customers.
- Visualized correlations and patterns across categorical and numerical features.
- Discovered that contract type, tenure, and monthly charges are strong churn indicators.

### 2. Data Preprocessing
- Handled missing values and incorrect data types.
- Converted categorical variables using one-hot encoding and label encoding.
- Scaled numerical features using standardization.
- Balanced the dataset if needed (e.g., using SMOTE or undersampling).

### 3. Feature Engineering
- Created new features based on tenure categories.
- Extracted insights from contract types and service combinations.

### 4. Model Building
Trained and evaluated multiple classification algorithms:
- Logistic Regression
- Decision Tree Classifier
- Random Forest Classifier
- (Optionally: KNN, SVM, Gradient Boosting)

### 5. Model Evaluation
Used multiple metrics to evaluate performance:
- Accuracy
- Precision & Recall
- F1 Score
- Confusion Matrix
- ROC Curve & AUC Score

The **Random Forest model** performed best with high recall for churn prediction.

---

## ğŸ“ˆ Sample Results

| Model                | Accuracy | Precision | Recall | F1 Score |
|---------------------|----------|-----------|--------|----------|
| Logistic Regression | 80.1%    | 72.3%     | 68.5%  | 70.3%    |
| Decision Tree       | 78.9%    | 70.1%     | 70.8%  | 70.4%    |
| Random Forest       | **84.2%**| **76.5%** | **74.9%** | **75.7%** |

---

## ğŸ“Œ Key Insights

- **Short-tenure customers** on **month-to-month contracts** are more likely to churn.
- Customers with **fiber optic internet** and **high monthly charges** showed higher churn rates.
- **Electronic billing** and **paperless billing** customers churn more frequently.
- Offering incentives for long-term contracts and bundling services can reduce churn.

---

## ğŸ“¦ Installation & Setup

### Requirements

- Python 3.x
- Jupyter Notebook
- pandas, numpy, scikit-learn, seaborn, matplotlib, joblib

### Install dependencies
```bash
pip install pandas numpy scikit-learn matplotlib seaborn joblib

